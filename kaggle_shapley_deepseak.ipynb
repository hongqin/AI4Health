{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024ce2a3-08fb-424b-9c46-711c81bb25dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (1.13.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (24.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba->shap) (0.43.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: kaggle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.6.17)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: packaging>20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (24.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kaggle) (3.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install shap xgboost scikit-learn pandas numpy matplotlib\n",
    "!pip install opencv-python\n",
    "! pip install kaggle pandas numpy scikit-learn xgboost shap opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a163046-c286-4f0a-9365-a8c58fc6a793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8402db3f-49a0-464c-9bbb-7b021558e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/hqin/.kaggle/kaggle.json'\n",
      "403 - Forbidden - Permission 'datasets.get' was denied\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rsna-pneumonia-detection-challenge.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Extract the dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m     16\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpneumonia_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/zipfile.py:1240\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rsna-pneumonia-detection-challenge.zip'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kaggle\n",
    "\n",
    "# Set Kaggle credentials (replace 'your-username' with actual Kaggle username)\n",
    "os.environ['KAGGLE_USERNAME'] = \"your-username\"\n",
    "os.environ['KAGGLE_KEY'] = \"your-kaggle-api-key\"\n",
    "\n",
    "# Download the dataset\n",
    "dataset = \"rsna-pneumonia-detection-challenge\"\n",
    "os.system(f\"kaggle datasets download -d {dataset}\")\n",
    "\n",
    "# Extract the dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(f\"{dataset}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"pneumonia_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b34915-7103-463d-9dfb-63787bc59fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98231501-9a38-49a8-a6e5-9db6bd22c312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af51222-246b-4eed-be7c-c124066e8619",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/a-pneumonia-detection-challenge/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(base_dir) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, f)) \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(prefix)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get image folders\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m image_dirs \u001b[38;5;241m=\u001b[39m BASEPATH \u001b[38;5;241m+\u001b[39m \u001b[43mlist_subdirectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASEPATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load labels\u001b[39;00m\n\u001b[1;32m     13\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(BASEPATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_1_train_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mlist_subdirectories\u001b[0;34m(base_dir, prefix)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"List all subdirectories in a given base directory.\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, f)) \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(prefix)]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/a-pneumonia-detection-challenge/'"
     ]
    }
   ],
   "source": [
    "# Set path to the dataset (replace with your actual data path)\n",
    "BASEPATH = '/kaggle/input/a-pneumonia-detection-challenge/'\n",
    "\n",
    "def list_subdirectories(base_dir, prefix=''):\n",
    "    \"\"\"List all subdirectories in a given base directory.\"\"\"\n",
    "    import os\n",
    "    return [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f)) and f.startswith(prefix)]\n",
    "\n",
    "# Get image folders\n",
    "image_dirs = BASEPATH + list_subdirectories(BASEPATH)\n",
    "\n",
    "# Load labels\n",
    "train_df = pd.read_csv(BASEPATH + 'stage_1_train_labels.csv')\n",
    "test_df = pd.read_csv(BASEPATH + 'stage_1_test_labels.csv')\n",
    "\n",
    "# Example: Filter images from the pneumonia and normal categories\n",
    "desired_classes = ['Pneumonia', 'Normal']\n",
    "train_df = train_df[train_df['Target'].isin(desired_classes)]\n",
    "test_df = test_df[test_df['Target'].isin(desired_classes)]\n",
    "\n",
    "def load_image(image_path, img_size=(128, 128)):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    import cv2\n",
    "    img = cv2.imread(image_path)\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img\n",
    "\n",
    "# Load and process training images\n",
    "train_images = []\n",
    "for _, row in train_df.iterrows():\n",
    "    image_path = BASEPATH + row['Path']\n",
    "    image = load_image(image_path, (64, 64))  # Resize to smaller size for efficiency\n",
    "    train_images.append(image)\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "X_train = np.array(train_images)\n",
    "y_train = train_df['Target'].values\n",
    "\n",
    "# Similarly, process test images\n",
    "test_images = []\n",
    "for _, row in test_df.iterrows():\n",
    "    image_path = BASEPATH + row['Path']\n",
    "    image = load_image(image_path, (64, 64))\n",
    "    test_images.append(image)\n",
    "\n",
    "X_test = np.array(test_images)\n",
    "y_test = test_df['Target'].values\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bcbf03-524b-4238-8adf-04a63886cfde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be89b23-88b0-4bf0-9c42-b742b67e2e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb5466-d2c9-4066-8f62-13cfba11f341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1aba3-fa2a-4459-9965-1b7a00ce6298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b11e9912-e8c4-4b65-8341-b7cea2fab701",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Training labels file not found at: /Users/hqin/github/AI4Health/stage_1_train_labels.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapTutorial\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()  \u001b[38;5;66;03m# Get current working directory\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m train_labels_csv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_1_train_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(train_labels_csv):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining labels file not found at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_labels_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m test_labels_csv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_1_test_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(test_labels_csv):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Training labels file not found at: /Users/hqin/github/AI4Health/stage_1_train_labels.csv"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import shap\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configure SHAP logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('shapTutorial')\n",
    "\n",
    "base_path = os.getcwd()  # Get current working directory\n",
    "train_df, test_df = load_data(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644211a0-8f32-40c7-b738-eab0d0968118",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m     test_df \u001b[38;5;241m=\u001b[39m test_df[test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_df, test_df\n\u001b[0;32m---> 36\u001b[0m base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n\u001b[1;32m     37\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m load_data(base_path)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(image_path, img_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)):\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and Preprocess Data\n",
    "def load_data(base_path):\n",
    "    \"\"\"Load image data from Kaggle's pneumonia detection challenge.\"\"\"\n",
    "    # Load labels\n",
    "    train_labels_csv = os.path.join(base_path, 'stage_1_train_labels.csv')\n",
    "    if not os.path.exists(train_labels_csv):\n",
    "        raise FileNotFoundError(f\"Training labels file not found at: {train_labels_csv}\")\n",
    "    \n",
    "    test_labels_csv = os.path.join(base_path, 'stage_1_test_labels.csv')\n",
    "    if not os.path.exists(test_labels_csv):\n",
    "        raise FileNotFoundError(f\"Testing labels file not found at: {test_labels_csv}\")\n",
    "\n",
    "    train_df = pd.read_csv(train_labels_csv)\n",
    "    test_df = pd.read_csv(test_labels_csv)\n",
    "\n",
    "    # Filter images for pneumonia and normal classes (0: Normal, 1: Pneumonia)\n",
    "    train_df = train_df[train_df['Target'].isin([0, 1])]\n",
    "    test_df = test_df[test_df['Target'].isin([0, 1])]\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "train_df, test_df = load_data(base_path)\n",
    "\n",
    "def load_image(image_path, img_size=(128, 128)):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img\n",
    "\n",
    "# Load and process training images\n",
    "train_images = []\n",
    "for _, row in train_df.iterrows():\n",
    "    image_path = os.path.join(base_path, row['Path'])\n",
    "    image = load_image(image_path, (64, 64))  # Resize to smaller size for efficiency\n",
    "    train_images.append(image)\n",
    "\n",
    "X_train = np.array(train_images)\n",
    "y_train = train_df['Target'].values.astype(int)\n",
    "\n",
    "# Similarly, process test images\n",
    "test_images = []\n",
    "for _, row in test_df.iterrows():\n",
    "    image_path = os.path.join(base_path, row['Path'])\n",
    "    image = load_image(image_path, (64, 64))\n",
    "    test_images.append(image)\n",
    "\n",
    "X_test = np.array(test_images)\n",
    "y_test = test_df['Target'].values.astype(int)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Split dataset into train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    gamma=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "logger.info('Starting training...')\n",
    "model.fit(X_train, y_train)\n",
    "val_score = model.score(X_val, y_val)\n",
    "logger.info(f\"Validation score: {val_score:.3f}\")\n",
    "\n",
    "# Initialize SHAP explainer with Tree explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values for each data point\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Create summary plot:\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.savefig('shap_summary.png')\n",
    "plt.close()\n",
    "\n",
    "# Create dependence plot for a single prediction:\n",
    "example_idx = 0\n",
    "sample_shap_values = shap_values[:, example_idx]  # Fixed indexing\n",
    "\n",
    "shap.dependence_plot(\n",
    "    'pixel_mean', \n",
    "    sample_shap_values,\n",
    "    X_test, \n",
    "    show=False\n",
    ")\n",
    "plt.savefig('dependence_plot.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ade92-69b5-4dcf-8a0b-017909ec1a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
