{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f798eae-2664-4467-9640-3c489d45ccc8",
   "metadata": {},
   "source": [
    "Notice that Facebook ESM has been archived. \n",
    "https://github.com/facebookresearch/esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da35b65-1e66-491f-ac3a-84bf648170ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping esm as it is not installed.\u001b[0m\u001b[33m\n",
      "Collecting git+https://github.com/facebookresearch/esm.git\n",
      "  Cloning https://github.com/facebookresearch/esm.git to /tmp/pip-req-build-sloajkh5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/esm.git /tmp/pip-req-build-sloajkh5\n",
      "  Resolved https://github.com/facebookresearch/esm.git to commit 2b369911bb5b4b0dda914521b9475cad1656b2ac\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from biopython) (2.2.2)\n",
      "Downloading biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: biopython\n",
      "Successfully installed biopython-1.85\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall esm\n",
    "! pip install git+https://github.com/facebookresearch/esm.git\n",
    "! pip install biopython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83085792-a022-47ba-93ba-b1c59d76777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (0.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting git+https://github.com/aqlaboratory/openfold.git\n",
      "  Cloning https://github.com/aqlaboratory/openfold.git to /tmp/pip-req-build-1_cpdnwh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/aqlaboratory/openfold.git /tmp/pip-req-build-1_cpdnwh\n",
      "  Resolved https://github.com/aqlaboratory/openfold.git to commit a1192c8d3a0f3004b1284aaf6437681e6b558c10\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dm-tree in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (from dm-tree) (2.1.0)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /opt/conda/lib/python3.10/site-packages (from dm-tree) (25.1.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from dm-tree) (2.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (from dm-tree) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install einops\n",
    "! pip install git+https://github.com/aqlaboratory/openfold.git\n",
    "! pip install dm-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd71eb-e295-4e13-a9fc-b931c2b9a0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367b42b-f25d-4b70-8bf0-59994e5a4cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b371127e-5973-40d8-85aa-756056055bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelcif in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (1.3)\n",
      "Requirement already satisfied: ihm>=1.7 in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (from modelcif) (1.8)\n",
      "Requirement already satisfied: msgpack in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (from ihm>=1.7->modelcif) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ml_collections in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: absl-py in /home/hqin/envs/default-pytorch-gpu-2.5.1/lib/python3.10/site-packages (from ml_collections) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.17.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections) (6.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf) (6.0.2)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install modelcif\n",
    "! pip install ml_collections\n",
    "! pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c79cb4-e6d2-436b-9bc3-6df2de2ed036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hqin/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t33_650M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a1cd0-d2ef-4b41-9814-c7292acf1f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t36_3B_UR50D.pt\" to /home/hqin/.cache/torch/hub/checkpoints/esm2_t36_3B_UR50D.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "model = esm.pretrained.esmfold_v1()\n",
    "model = model.eval().cuda()\n",
    "\n",
    "# Optionally, uncomment to set a chunk size for axial attention. This can help reduce memory.\n",
    "# Lower sizes will have lower memory requirements at the cost of increased speed.\n",
    "# model.set_chunk_size(128)\n",
    "\n",
    "sequence = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
    "# Multimer prediction can be done with chains separated by ':'\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.infer_pdb(sequence)\n",
    "\n",
    "with open(\"result.pdb\", \"w\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "import biotite.structure.io as bsio\n",
    "struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
    "print(struct.b_factor.mean())  # this will be the pLDDT\n",
    "# 88.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b8c8a-ba2a-4c13-9c47-da576adccb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
